{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import no_grad, tensor\n",
    "from torch.nn import LSTM, Linear, Module, MSELoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "def prepare_dataset_for_lstm(series, seq_length: int = 4):\n",
    "    setX: list = []\n",
    "    setY: list = []\n",
    "    for i in range(len(series) - seq_length):\n",
    "        past = series[i : i + seq_length]\n",
    "        future = series[i + 1 : i + seq_length + 1]\n",
    "        setX.append(past)\n",
    "        setY.append(future)\n",
    "    return tensor(setX), tensor(setY)\n",
    "\n",
    "\n",
    "class DS_LSTM(Module):\n",
    "    def __init__(self, train, input_size: int = 1, hidden_size: int = 50, num_layers: int = 1, length: int = 4):\n",
    "        super().__init__()\n",
    "        self.lstm = LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.linear = Linear(hidden_size, 1)\n",
    "        self.optimizer = Adam(self.parameters())\n",
    "        self.loss_fn = MSELoss()\n",
    "\n",
    "        trnX, trnY = prepare_dataset_for_lstm(train, seq_length=length)\n",
    "        self.loader = DataLoader(TensorDataset(trnX, trnY), shuffle=True, batch_size=len(train) // 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "    def fit(self):\n",
    "        self.train()\n",
    "        for batchX, batchY in self.loader:\n",
    "            y_pred = self(batchX)\n",
    "            loss = self.loss_fn(y_pred, batchY)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        return loss\n",
    "\n",
    "    def predict(self, X):\n",
    "        with no_grad():\n",
    "            y_pred = self(X)\n",
    "        return y_pred[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv, DataFrame, Series\n",
    "from dslabs_functions import series_train_test_split\n",
    "\n",
    "filename: str = \"/home/mina/Documents/portugal/dataScience/set_1_diff_twice.csv\"\n",
    "file_tag: str = \"Set 1\"\n",
    "target: str = \"Manhattan\"\n",
    "timecol: str = \"Date\"\n",
    "\n",
    "measure: str = \"R2\"\n",
    "\n",
    "data: DataFrame = read_csv(filename, index_col=timecol, sep=\",\", decimal=\".\", parse_dates=True)\n",
    "series = data[[target]].values.astype(\"float32\")\n",
    "\n",
    "train_size = int(len(series) * 0.90)\n",
    "train, test = series[:train_size], series[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11586.5498, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = DS_LSTM(train, input_size=1, hidden_size=50, num_layers=1)\n",
    "loss = model.fit()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq length=2 hidden_units=25 nr_episodes=0 -0.09235548973083496\n",
      "seq length=2 hidden_units=25 nr_episodes=300 0.05259537696838379\n",
      "seq length=2 hidden_units=25 nr_episodes=600 -0.0417633056640625\n",
      "seq length=2 hidden_units=25 nr_episodes=900 -0.23392903804779053\n",
      "seq length=2 hidden_units=25 nr_episodes=1200 -0.4513418674468994\n",
      "seq length=2 hidden_units=25 nr_episodes=1500 -0.6584231853485107\n",
      "seq length=2 hidden_units=25 nr_episodes=1800 -0.8281580209732056\n",
      "seq length=2 hidden_units=25 nr_episodes=2100 -0.8927006721496582\n",
      "seq length=2 hidden_units=25 nr_episodes=2400 -1.042851448059082\n",
      "seq length=2 hidden_units=25 nr_episodes=2700 -1.1363623142242432\n",
      "seq length=2 hidden_units=25 nr_episodes=3000 -1.2134921550750732\n",
      "seq length=2 hidden_units=50 nr_episodes=0 -0.0924983024597168\n",
      "seq length=2 hidden_units=50 nr_episodes=300 -0.16160821914672852\n",
      "seq length=2 hidden_units=50 nr_episodes=600 -0.5159695148468018\n",
      "seq length=2 hidden_units=50 nr_episodes=900 -0.6850854158401489\n",
      "seq length=2 hidden_units=50 nr_episodes=1200 -0.772127628326416\n",
      "seq length=2 hidden_units=50 nr_episodes=1500 -0.8582720756530762\n",
      "seq length=2 hidden_units=50 nr_episodes=1800 -0.9850794076919556\n"
     ]
    }
   ],
   "source": [
    "from dslabs_functions import HEIGHT, plot_multiline_chart\n",
    "from copy import deepcopy\n",
    "\n",
    "from matplotlib.pyplot import figure, savefig, subplots\n",
    "from dslabs_functions import FORECAST_MEASURES, DELTA_IMPROVE, plot_multiline_chart\n",
    "\n",
    "\n",
    "def lstm_study(train, test, nr_episodes: int = 1000, measure: str = \"R2\"):\n",
    "    sequence_size = [2, 4, 8]\n",
    "    nr_hidden_units = [25, 50, 100]\n",
    "\n",
    "    step: int = nr_episodes // 10\n",
    "    episodes = [1] + list(range(0, nr_episodes + 1, step))[1:]\n",
    "    flag = measure == \"R2\" or measure == \"MAPE\"\n",
    "    best_model = None\n",
    "    best_params: dict = {\"name\": \"LSTM\", \"metric\": measure, \"params\": ()}\n",
    "    best_performance: float = -100000\n",
    "\n",
    "    _, axs = subplots(1, len(sequence_size), figsize=(len(sequence_size) * HEIGHT, HEIGHT))\n",
    "\n",
    "    for i in range(len(sequence_size)):\n",
    "        length = sequence_size[i]\n",
    "        tstX, tstY = prepare_dataset_for_lstm(test, seq_length=length)\n",
    "\n",
    "        values = {}\n",
    "        for hidden in nr_hidden_units:\n",
    "            yvalues = []\n",
    "            model = DS_LSTM(train, hidden_size=hidden)\n",
    "            for n in range(0, nr_episodes + 1):\n",
    "                model.fit()\n",
    "                if n % step == 0:\n",
    "                    prd_tst = model.predict(tstX)\n",
    "                    eval: float = FORECAST_MEASURES[measure](test[length:], prd_tst)\n",
    "                    print(f\"seq length={length} hidden_units={hidden} nr_episodes={n}\", eval)\n",
    "                    if eval > best_performance and abs(eval - best_performance) > DELTA_IMPROVE:\n",
    "                        best_performance: float = eval\n",
    "                        best_params[\"params\"] = (length, hidden, n)\n",
    "                        best_model = deepcopy(model)\n",
    "                    yvalues.append(eval)\n",
    "            values[hidden] = yvalues\n",
    "        plot_multiline_chart(\n",
    "            episodes,\n",
    "            values,\n",
    "            ax=axs[i],\n",
    "            title=f\"LSTM seq length={length} ({measure})\",\n",
    "            xlabel=\"nr episodes\",\n",
    "            ylabel=measure,\n",
    "            percentage=flag,\n",
    "        )\n",
    "    print(\n",
    "        f\"LSTM best results achieved with length={best_params[\"params\"][0]} hidden_units={best_params[\"params\"][1]} and nr_episodes={best_params[\"params\"][2]}) ==> measure={best_performance:.2f}\"\n",
    "    )\n",
    "    return best_model, best_params\n",
    "\n",
    "\n",
    "best_model, best_params = lstm_study(train, test, nr_episodes=3000, measure=measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dslabs_functions import plot_forecasting_eval\n",
    "\n",
    "params = best_params[\"params\"]\n",
    "best_length = params[0]\n",
    "trnX, trnY = prepare_dataset_for_lstm(train, seq_length=best_length)\n",
    "tstX, tstY = prepare_dataset_for_lstm(test, seq_length=best_length)\n",
    "\n",
    "prd_trn = best_model.predict(trnX)\n",
    "prd_tst = best_model.predict(tstX)\n",
    "\n",
    "plot_forecasting_eval(\n",
    "    train[best_length:],\n",
    "    test[best_length:],\n",
    "    prd_trn,\n",
    "    prd_tst,\n",
    "    title=f\"{file_tag} - LSTM (length={best_length}, hidden={params[1]}, epochs={params[2]})\",\n",
    ")\n",
    "savefig(f\"/home/mina/Documents/portugal/dataScience/Data_science_project/MODELS’ EVALUATION/images_LSTM/{file_tag}_lstms_{measure}_eval.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dslabs_functions import plot_forecasting_series\n",
    "\n",
    "series = data[[target]]\n",
    "train, test = series[:train_size], series[train_size:]\n",
    "pred_series: Series = Series(prd_tst.numpy().ravel(), index=test.index[best_length:])\n",
    "\n",
    "plot_forecasting_series(\n",
    "    train[best_length:],\n",
    "    test[best_length:],\n",
    "    pred_series,\n",
    "    title=f\"{file_tag} - LSTMs \",\n",
    "    xlabel=timecol,\n",
    "    ylabel=target,\n",
    ")\n",
    "savefig(f\"/home/mina/Documents/portugal/dataScience/Data_science_project/MODELS’ EVALUATION/images_LSTM/{file_tag}_lstms_{measure}_forecast.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
